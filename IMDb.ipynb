{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "from DecisionTrees import *\n",
    "import pandas as pd\n",
    "def loadimdb_train(train=True):\n",
    "    if(train == True):\n",
    "        pathneg= \"./aclImdb/train/neg/\"\n",
    "        pathpos=\"./aclImdb/train/pos/\"\n",
    "    else:\n",
    "        pathneg= \"./aclImdb/test/neg/\"\n",
    "        pathpos=\"./aclImdb/test/pos/\"\n",
    "    negfiles=[]\n",
    "    posfiles=[]\n",
    "    for file in glob.glob(pathneg+\"*.txt\"):\n",
    "        f = open(file, \"r\")\n",
    "        negfiles.append(f.read())\n",
    "    for file in glob.glob(pathpos+\"*.txt\"):\n",
    "        f = open(file, \"r\")\n",
    "        posfiles.append(f.read())\n",
    "        \n",
    "    neg=list(zip(negfiles,[0]*len(negfiles)))\n",
    "    pos=list(zip(posfiles,[1]*len(posfiles)))\n",
    "    sentiments = neg + pos\n",
    "    return(sentiments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = loadimdb_train()\n",
    "testsentiments = loadimdb_train(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = pd.DataFrame(sentiments)\n",
    "ltest = pd.DataFrame(testsentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.data = l[0]\n",
    "data.target=l[1]\n",
    "testdata.data=ltest[0]\n",
    "testdata.target=ltest[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.target_names = ['pos','neg']\n",
    "testdata.target_names=['pos','neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.734 (std: 0.009)\n",
      "Parameters: {'tfidf__norm': 'l1', 'clf__splitter': 'random', 'clf__min_samples_split': 100, 'clf__min_samples_leaf': 5, 'clf__max_leaf_nodes': 50, 'clf__max_features': None, 'clf__max_depth': 100, 'clf__class_weight': 'balanced'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.723 (std: 0.009)\n",
      "Parameters: {'tfidf__norm': 'l1', 'clf__splitter': 'best', 'clf__min_samples_split': 100, 'clf__min_samples_leaf': 100, 'clf__max_leaf_nodes': 200, 'clf__max_features': None, 'clf__max_depth': 50, 'clf__class_weight': 'balanced'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.721 (std: 0.013)\n",
      "Parameters: {'tfidf__norm': 'l1', 'clf__splitter': 'best', 'clf__min_samples_split': 2, 'clf__min_samples_leaf': 50, 'clf__max_leaf_nodes': 20, 'clf__max_features': None, 'clf__max_depth': None, 'clf__class_weight': None}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.717 (std: 0.008)\n",
      "Parameters: {'tfidf__norm': 'l1', 'clf__splitter': 'best', 'clf__min_samples_split': 100, 'clf__min_samples_leaf': 10, 'clf__max_leaf_nodes': None, 'clf__max_features': None, 'clf__max_depth': 100, 'clf__class_weight': 'balanced'}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: 0.592 (std: 0.010)\n",
      "Parameters: {'tfidf__norm': 'l1', 'clf__splitter': 'random', 'clf__min_samples_split': 100, 'clf__min_samples_leaf': 1, 'clf__max_leaf_nodes': 50, 'clf__max_features': 'sqrt', 'clf__max_depth': 100, 'clf__class_weight': 'balanced'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(dt.cv_results_,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.851 (std: 0.002)\n",
      "Parameters: {'clf__n_estimators': 600, 'clf__learning_rate': 1.5, 'clf__base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'clf__algorithm': 'SAMME'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.847 (std: 0.001)\n",
      "Parameters: {'clf__n_estimators': 600, 'clf__learning_rate': 0.9, 'clf__base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'clf__algorithm': 'SAMME'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.841 (std: 0.004)\n",
      "Parameters: {'clf__n_estimators': 600, 'clf__learning_rate': 0.5, 'clf__base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'clf__algorithm': 'SAMME'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.834 (std: 0.006)\n",
      "Parameters: {'clf__n_estimators': 200, 'clf__learning_rate': 1, 'clf__base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'clf__algorithm': 'SAMME.R'}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: 0.821 (std: 0.004)\n",
      "Parameters: {'clf__n_estimators': 100, 'clf__learning_rate': 1.5, 'clf__base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'clf__algorithm': 'SAMME'}\n",
      "\n",
      "Model with rank: 6\n",
      "Mean validation score: 0.807 (std: 0.002)\n",
      "Parameters: {'clf__n_estimators': 100, 'clf__learning_rate': 1.5, 'clf__base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'clf__algorithm': 'SAMME.R'}\n",
      "\n",
      "Model with rank: 7\n",
      "Mean validation score: 0.795 (std: 0.003)\n",
      "Parameters: {'clf__n_estimators': 100, 'clf__learning_rate': 0.1, 'clf__base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'clf__algorithm': 'SAMME.R'}\n",
      "\n",
      "Model with rank: 8\n",
      "Mean validation score: 0.758 (std: 0.004)\n",
      "Parameters: {'clf__n_estimators': 10, 'clf__learning_rate': 0.9, 'clf__base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'clf__algorithm': 'SAMME.R'}\n",
      "\n",
      "Model with rank: 9\n",
      "Mean validation score: 0.758 (std: 0.004)\n",
      "Parameters: {'clf__n_estimators': 10, 'clf__learning_rate': 1, 'clf__base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'clf__algorithm': 'SAMME.R'}\n",
      "\n",
      "Model with rank: 10\n",
      "Mean validation score: 0.691 (std: 0.008)\n",
      "Parameters: {'clf__n_estimators': 10, 'clf__learning_rate': 0.1, 'clf__base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'clf__algorithm': 'SAMME.R'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(bestada.cv_results_,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rgao/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/Rgao/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SearchCV took 16378.64 seconds for 10 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.851 (std: 0.002)\n",
      "Parameters: {'clf__n_estimators': 600, 'clf__learning_rate': 1.5, 'clf__base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'clf__algorithm': 'SAMME'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.847 (std: 0.001)\n",
      "Parameters: {'clf__n_estimators': 600, 'clf__learning_rate': 0.9, 'clf__base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'clf__algorithm': 'SAMME'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.841 (std: 0.004)\n",
      "Parameters: {'clf__n_estimators': 600, 'clf__learning_rate': 0.5, 'clf__base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'clf__algorithm': 'SAMME'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt=run_pipeline(data)\n",
    "bestada = run_pipeline(data,AdaBoostClassifier(random_state=0),\n",
    "                      params={\n",
    "                             'clf__base_estimator':[DecisionTreeClassifier(max_depth=2)],\n",
    "                             'clf__n_estimators': [10,100,200,600],\n",
    "                             'clf__learning_rate':[.5,.9,1,1.5],\n",
    "                             'clf__algorithm':['SAMME.R','SAMME'],\n",
    "                             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from time import time\n",
    "import numpy as np\n",
    "def load_data(data, input_features, target_feature, cat_features=None, num_features=None, txt_features=None):\n",
    "    all_features = input_features + [target_feature]\n",
    "    print(data.values.shape)\n",
    "    data = data[all_features]\n",
    "    data.dropna(subset=[target_feature], inplace=True)\n",
    "\n",
    "    # change categorical features to numeric code\n",
    "    if(cat_features!=None):\n",
    "        data[cat_features] = data[cat_features].astype('category')\n",
    "        data[cat_features] = data[cat_features].apply(lambda x: x.cat.codes)\n",
    "    # replace nan with 0 in numerical features\n",
    "    if(num_features!=None):\n",
    "        data[num_features] = data[num_features].fillna(0.)\n",
    "        for feature in num_features:\n",
    "            data[feature] = data[feature].apply(lambda x: replace_string(x))\n",
    "    if(txt_features!=None):\n",
    "        if txt_features:\n",
    "            data[txt_features] = data[txt_features].fillna('')\n",
    "\n",
    "    return data\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\"\n",
    "                  .format(results['mean_test_score'][candidate],\n",
    "                          results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "            \n",
    "from sklearn.pipeline import Pipeline\n",
    "def build_pipeline(model = DecisionTreeClassifier(random_state=0, criterion='gini')):\n",
    "    return Pipeline(([\n",
    "        ('vect',CountVectorizer(stop_words='english')),\n",
    "        ('tfidf',TfidfTransformer(use_idf= True)),\n",
    "        ('clf',model),\n",
    "    ]))\n",
    "def run_pipeline(text_ds,model=DecisionTreeClassifier(random_state=0, criterion='gini'),\n",
    "                 gridsearch =False,\n",
    "                 params ={'clf__splitter':['best','random'],\n",
    "                          'tfidf__norm':['l2','l1'],\n",
    "                                    'clf__max_features':[\"auto\",\"sqrt\",\"log2\",None],\n",
    "                                    'clf__class_weight': ['balanced',None],\n",
    "                                    'clf__min_samples_leaf':[1,5,20,50,100],\n",
    "                                    'clf__min_samples_split':[2,5,20,50,100],\n",
    "                                    'clf__max_depth':[25,50,100,None],\n",
    "                                    'clf__max_leaf_nodes':[20,50,200,None]},\n",
    "                ):\n",
    "    pl = build_pipeline(model)\n",
    "    pl.fit(text_ds.data,text_ds.target)\n",
    "    \n",
    "    if(gridsearch==True):\n",
    "        search = GridSearchCV(pl, params, n_jobs=4,verbose=1)\n",
    "    else:\n",
    "        search =  RandomizedSearchCV(pl, param_distributions=params,\n",
    "                                   n_iter=20)\n",
    "    start = time()\n",
    "    search.fit(text_ds.data,text_ds.target)\n",
    "    search.fit(data.data, data.target)\n",
    "    print(\"SearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), 20))\n",
    "    report(search.cv_results_)\n",
    "    return(search)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words='english', strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabular...\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 DecisionTreeClassifier(class_weight='balanced',\n",
       "                                        criterion='gini', max_depth=100,\n",
       "                                        max_features=None, max_leaf_nodes=50,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=5,\n",
       "                                        min_samples_split=100,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        presort=False, random_state=None,\n",
       "                                        splitter='random'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ba=build_pipeline(AdaBoostClassifier(n_estimators=600,learning_rate=1.5,base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2),algorithm='SAMME'))\n",
    "ba.fit(data.data,data.target)\n",
    "bd=build_pipeline(DecisionTreeClassifier(class_weight='balanced',criterion='gini',max_depth=100,max_features=None,max_leaf_nodes=50,min_samples_leaf=5,splitter='random',min_samples_split=100))\n",
    "bd.fit(data.data,data.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7578\n",
      "0.85104\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cross_validate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4ae3e28e65a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0madapred\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdtcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplaindt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0madacv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplainada\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cross_validate' is not defined"
     ]
    }
   ],
   "source": [
    "dtpred = bd.predict(testdata.data)\n",
    "print(accuracy_score(dtpred, testdata.target))\n",
    "adapred= ba.predict(testdata.data)\n",
    "print(accuracy_score(adapred, testdata.target))\n",
    "dtcv=cross_validate(plaindt,data.data,data.target,3)\n",
    "adacv=cross_validate(plainada,data.data,data.target,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "def cross_validate(model,X_input,target,cv):\n",
    "    return(cross_val_score(model, X_input, target, cv=cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.70348\n",
      "0.8034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.79841613, 0.8012959 , 0.79848776])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plaindt = build_pipeline(DecisionTreeClassifier())\n",
    "plainada = build_pipeline(AdaBoostClassifier())\n",
    "plaindt.fit(data.data,data.target)\n",
    "plainada.fit(data.data,data.target)\n",
    "\n",
    "dtpred = plaindt.predict(testdata.data)\n",
    "print(accuracy_score(dtpred, testdata.target))\n",
    "adapred= plainada.predict(testdata.data)\n",
    "print(accuracy_score(adapred, testdata.target))\n",
    "dtcv=cross_validate(plaindt,data.data,data.target,3)\n",
    "adacv=cross_validate(plainada,data.data,data.target,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8833 3746]\n",
      " [3667 8754]]\n",
      "[[ 9564  1979]\n",
      " [ 2936 10521]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(dtpred,testdata.target))\n",
    "print(confusion_matrix(adapred,testdata.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dtcv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-3878a479f05d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madacv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madacv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dtcv' is not defined"
     ]
    }
   ],
   "source": [
    "print(np.mean(dtcv))\n",
    "print(np.std(dtcv))\n",
    "print(np.mean(adacv))\n",
    "print(np.std(adacv))\n",
    "print(confusion_matrix(dtpred,testdata.target))\n",
    "print(confusion_matrix(adapred,testdata.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "badapred=bestada.predict(testdata.data)\n",
    "print(accuracy_score(badapred, testdata.target))\n",
    "bdtpred = dt.predict(testdata.data)\n",
    "print(accuracy_score(bdtpred, testdata.target))\n",
    "bestadacv=cross_validate(bestada,data.data,data.target,3)\n",
    "bdtcv=cross_validate(dt,data.data,data.target,3)\n",
    "\n",
    "print(np.mean(bdtcv))\n",
    "print(np.std(bdtcv))\n",
    "print(np.mean(bestadacv))\n",
    "print(np.std(bestadacv))\n",
    "\n",
    "print(confusion_matrix(bdtpred,testdata.target))\n",
    "print(confusion_matrix(badapred,testdata.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=Non...\n",
       "                 TfidfTransformer(norm='l1', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 DecisionTreeClassifier(class_weight='balanced',\n",
       "                                        criterion='gini', max_depth=100,\n",
       "                                        max_features=None, max_leaf_nodes=50,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=5,\n",
       "                                        min_samples_split=100,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        presort=False, random_state=0,\n",
       "                                        splitter='random'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=Non...\n",
       "                                    base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                                          criterion='gini',\n",
       "                                                                          max_depth=2,\n",
       "                                                                          max_features=None,\n",
       "                                                                          max_leaf_nodes=None,\n",
       "                                                                          min_impurity_decrease=0.0,\n",
       "                                                                          min_impurity_split=None,\n",
       "                                                                          min_samples_leaf=1,\n",
       "                                                                          min_samples_split=2,\n",
       "                                                                          min_weight_fraction_leaf=0.0,\n",
       "                                                                          presort=False,\n",
       "                                                                          random_state=None,\n",
       "                                                                          splitter='best'),\n",
       "                                    learning_rate=1.5, n_estimators=600,\n",
       "                                    random_state=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestada.best_estimator_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
