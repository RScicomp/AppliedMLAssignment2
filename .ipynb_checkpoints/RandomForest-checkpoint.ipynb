{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.pipeline import Pipeline\n",
    "from time import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata=sklearn.datasets.fetch_20newsgroups(data_home=None, subset='test', categories=None, shuffle=True, random_state=42, remove=(), download_if_missing=True)\n",
    "data=sklearn.datasets.fetch_20newsgroups(data_home=None, subset='train', categories=None, shuffle=True, random_state=42, remove=(), download_if_missing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\"\n",
    "                  .format(results['mean_test_score'][candidate],\n",
    "                          results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "            \n",
    "def build_pipeline_RF(model = RandomForestClassifier(random_state=0)):\n",
    "    return Pipeline(([\n",
    "        ('vect',CountVectorizer()),\n",
    "        ('tfidf',TfidfTransformer()),\n",
    "        ('clf',model),\n",
    "    ]))\n",
    "\n",
    "\n",
    "def run_pipeline_RF(text_ds,model=RandomForestClassifier(random_state=0),\n",
    "                 gridsearch = False,\n",
    "                 params ={'clf__criterion':['gini','entropy'],\n",
    "                          'clf__n_estimators':[100,200,400,800]\n",
    "                         }):\n",
    "    \n",
    "    pl = build_pipeline_RF(model)\n",
    "    pl.fit(text_ds.data,text_ds.target)\n",
    "    if(gridsearch != None):\n",
    "        if(gridsearch==True):\n",
    "            search = GridSearchCV(pl, params, n_jobs=-1,verbose=1)\n",
    "        else:\n",
    "            search =RandomizedSearchCV(pl, param_distributions=params,\n",
    "                                       n_iter=10)\n",
    "        start = time()\n",
    "        search.fit(text_ds.data,text_ds.target)\n",
    "        search.fit(data.data, data.target)\n",
    "        print(\"SearchCV took %.2f seconds for %d candidates\"\n",
    "          \" parameter settings.\" % ((time() - start), 10))\n",
    "        report(search.cv_results_)\n",
    "        return(search)\n",
    "    else:\n",
    "        return(pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "plainLFPredict = run_pipeline_RF(data,gridsearch=None).predict(testdata.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5584174190122145"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(plainLF == testdata.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:  7.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:  7.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SearchCV took 1346.24 seconds for 10 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.848 (std: 0.009)\n",
      "Parameters: {'clf__criterion': 'gini', 'clf__n_estimators': 800}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.843 (std: 0.012)\n",
      "Parameters: {'clf__criterion': 'gini', 'clf__n_estimators': 400}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.838 (std: 0.010)\n",
      "Parameters: {'clf__criterion': 'gini', 'clf__n_estimators': 200}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bestLF=run_pipeline_RF(data,gridsearch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5584174190122145\n",
      "0.789830058417419\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "bestLFPredict = bestLF.predict(testdata.data)\n",
    "print(accuracy_score(plainLFPredict, testdata.target))\n",
    "print(accuracy_score(bestLFPredict, testdata.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[203   1   1   1   0   0   0   1   0   0   0   0   3   7   1   4   0  18\n",
      "    2  34]\n",
      " [  3 292  20  18   5  35   2   8   1   2   2   5  26  17   9   1   2   0\n",
      "    3   4]\n",
      " [  1  16 318  35   9  46   1   1   0   1   0   2  13   2   0   1   0   0\n",
      "    0   1]\n",
      " [  0  11  18 275  21   5   6   1   2   0   0   2  27   5   0   1   1   0\n",
      "    0   0]\n",
      " [  3  11  10  17 311   4   6   1   1   1   2   1  16   3   3   0   1   1\n",
      "    3   1]\n",
      " [  0  26  11   4   2 287   0   1   1   0   0   0  11   5   3   1   0   4\n",
      "    0   0]\n",
      " [  4   7   2  15  13   4 362  15   8   5   3   2   8  18   3   2   6   1\n",
      "    3   1]\n",
      " [  0   1   0   4   1   1   3 325  11   0   0   1  16   9   3   0   4   1\n",
      "    2   2]\n",
      " [  0   2   0   0   1   0   0  16 365   1   0   0   7   1   1   0   1   0\n",
      "    0   0]\n",
      " [  5   1   5   0   6   2   2   2   2 371  12   6   6  10   3   2   4   8\n",
      "    2   2]\n",
      " [  2   2   0   1   0   0   0   1   0  16 378   0   2   3   1   0   0   7\n",
      "    1   2]\n",
      " [  3   2   1   2   1   5   1   1   1   0   0 369  15   1   1   0   7   2\n",
      "    3   1]\n",
      " [  0   3   1  17  11   1   4  11   2   0   0   1 224  20   3   3   2   2\n",
      "    0   1]\n",
      " [  8   2   0   0   2   0   1   1   1   0   0   0   4 278   5   2   3   1\n",
      "    8   9]\n",
      " [  5   7   4   3   2   5   2   1   0   0   1   2  12   3 353   2   3   1\n",
      "   12   7]\n",
      " [ 57   3   0   0   0   0   0   1   0   0   0   0   3   7   2 378   2  10\n",
      "    5  79]\n",
      " [  5   1   0   0   0   0   0   8   2   0   0   3   0   3   0   0 322   5\n",
      "  110  22]\n",
      " [  7   1   1   0   0   0   0   0   0   0   0   0   0   1   1   0   1 309\n",
      "    4   3]\n",
      " [  0   0   2   0   0   0   0   1   1   0   1   2   0   3   2   0   5   4\n",
      "  152   5]\n",
      " [ 13   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   2\n",
      "    0  77]]\n",
      "[[176   5   5   4   3   6   0  11   4  13   3   1   6  16   8  19   5  28\n",
      "   11  41]\n",
      " [  3 213  67  52  37  43  15  25   9  13   7  10  52  34  18  13   6   1\n",
      "    5   8]\n",
      " [  4  42 209  52  24  59  15  17   9  12   2  13  40  14  10   6   4   2\n",
      "    7   7]\n",
      " [  4  20  39 162  61  22  22  17   8   7   3  11  33  14   9   6   5   4\n",
      "    7   4]\n",
      " [  8  17  13  45 183  21  15  28  11  11   3  10  27  16  13  12   3   6\n",
      "    6   5]\n",
      " [  4  33  22  12   7 202   3  13   4   8   3   3  18  13   6   4   2   4\n",
      "    4   3]\n",
      " [  0  16   5  13  26   3 294  14  14  11   9   6  19   9  13   5   7   4\n",
      "    6   3]\n",
      " [ 10   5   9  11   5   7  10 210  25  12   6   8  22  23  15   8  11   7\n",
      "    6   9]\n",
      " [  4   4   3   1   3   2   3  22 285   6   5   7  14  16  10  10   7   7\n",
      "    8   9]\n",
      " [  7   2   1   4   8   3   2   7   4 254  39   4   6  12   8   1  11   7\n",
      "    6   4]\n",
      " [  7   0   4   1   3   0   4   2   0  28 310   1   6  12   2   0   5  10\n",
      "    5   3]\n",
      " [  6   3   5   4   4   2   1   1   5   3   0 303  15   6   9   2  17   7\n",
      "   12   6]\n",
      " [  3   9   1  20   9  11   3   8   3   2   3   4 102  22  14   5   7   5\n",
      "    7   4]\n",
      " [  5   4   2   3   3   3   0   5   8   1   0   2   9 168  14   6  13   8\n",
      "   10  11]\n",
      " [  3   8   3   4   3   4   1   5   1   5   1   3   8   2 236   4   6   8\n",
      "   11   4]\n",
      " [ 54   3   1   1   2   1   2   3   0   2   4   3   9   7   3 287   9  10\n",
      "   10  60]\n",
      " [  5   2   1   0   1   2   0   7   5   2   0   4   4   1   2   0 231  10\n",
      "   84  11]\n",
      " [  2   1   1   0   0   1   0   0   1   4   0   1   0   2   2   2   3 234\n",
      "    4   6]\n",
      " [  1   1   2   3   3   3   0   0   0   3   1   1   2   4   2   2   8  10\n",
      "   99   5]\n",
      " [ 13   1   1   0   0   0   0   1   2   0   0   1   1   5   0   6   4   4\n",
      "    2  48]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(bestLFPredict,testdata.target))\n",
    "print(confusion_matrix(plainLFPredict,testdata.target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
