{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import datasets\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "def load_data(data, input_features, target_feature, cat_features=None, num_features=None, txt_features=None):\n",
    "    all_features = input_features + [target_feature]\n",
    "    print(data.values.shape)\n",
    "    data = data[all_features]\n",
    "    data.dropna(subset=[target_feature], inplace=True)\n",
    "\n",
    "    # change categorical features to numeric code\n",
    "    if(cat_features!=None):\n",
    "        data[cat_features] = data[cat_features].astype('category')\n",
    "        data[cat_features] = data[cat_features].apply(lambda x: x.cat.codes)\n",
    "    # replace nan with 0 in numerical features\n",
    "    if(num_features!=None):\n",
    "        data[num_features] = data[num_features].fillna(0.)\n",
    "        for feature in num_features:\n",
    "            data[feature] = data[feature].apply(lambda x: replace_string(x))\n",
    "    if(txt_features!=None):\n",
    "        if txt_features:\n",
    "            data[txt_features] = data[txt_features].fillna('')\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata=sklearn.datasets.fetch_20newsgroups(data_home=None, subset='test', categories=None, shuffle=True, random_state=42, remove=(['headers', 'footers', 'quotes']), download_if_missing=True)\n",
    "data=sklearn.datasets.fetch_20newsgroups(data_home=None, subset='train', categories=None, shuffle=True, random_state=42, remove=(['headers', 'footers', 'quotes']), download_if_missing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(list(zip(data['data'],data['target'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['text','category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercase\n",
    "data['text'] = [data.lower() for data in data['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwords\n",
    "stop_words = set(stopwords.words(‘english’))\n",
    "from nltk.tokenize import word_tokenize\n",
    "data['text'] = [word_tokenize(data) for data in data['text'] word_tokenize(input_str)]\n",
    "result = [i for i in tokens if not i in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#Count vectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(data.data)\n",
    "print(X_train_counts.shape)\n",
    "#counts\n",
    "count_vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#frequencies\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loguniform(low=0, high=1, size=None):\n",
    "    return stats.reciprocal(np.exp(low), np.exp(high))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomizedsearch(X,y,model=DecisionTreeClassifier(random_state=0,criterion ='gini'),\n",
    "                     n_iter_search=20,\n",
    "                      param_dist = {'splitter':['best','random'],\n",
    "                                    'max_features':[\"auto\",\"sqrt\",\"log2\",None],\n",
    "                                    'class_weight': ['balanced',None],\n",
    "                                    'min_samples_leaf':[1,5,10,25,50,100],\n",
    "                                    'min_samples_split':[2,5,10,25,50,100],\n",
    "                                    'max_depth':[10,25,50,100,200]}):\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "    start = time()\n",
    "    random_search.fit(X_train_tf, data.target)\n",
    "    print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "    report(random_search.cv_results_)\n",
    "    return(random_search)\n",
    "    \n",
    "def gridsearch(X,y,model=DecisionTreeClassifier(random_state=0,criterion ='gini'),\n",
    "               param_grid = {'splitter':['best','random'],\n",
    "                                    'max_features':[\"auto\",\"sqrt\",\"log2\",None],\n",
    "                                    'class_weight': ['balanced',None],\n",
    "                                    'min_samples_leaf':[1,5,10,25,50,100],\n",
    "                                    'min_samples_split':[2,5,10,25,50,100],\n",
    "                                    'max_depth':[10,25,50,100,200]}):\n",
    "    grid_search = GridSearchCV(model, param_grid=param_grid)\n",
    "    start = time()\n",
    "    grid_search.fit(X, y)\n",
    "    print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "    report(grid_search.cv_results_)\n",
    "    return(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rgao/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 125.88 seconds for 20 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.613 (std: 0.006)\n",
      "Parameters: {'splitter': 'best', 'min_samples_split': 25, 'min_samples_leaf': 5, 'max_features': None, 'max_depth': 100, 'class_weight': None}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.595 (std: 0.014)\n",
      "Parameters: {'splitter': 'random', 'min_samples_split': 100, 'min_samples_leaf': 10, 'max_features': None, 'max_depth': 100, 'class_weight': 'balanced'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.519 (std: 0.007)\n",
      "Parameters: {'splitter': 'best', 'min_samples_split': 100, 'min_samples_leaf': 50, 'max_features': None, 'max_depth': 50, 'class_weight': 'balanced'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rs=randomizedsearch(X_train_tf,data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rgao/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 10770.57 seconds for 2880 candidate parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.635 (std: 0.017)\n",
      "Parameters: {'class_weight': 'balanced', 'max_depth': 200, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 50, 'splitter': 'random'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.632 (std: 0.007)\n",
      "Parameters: {'class_weight': None, 'max_depth': 200, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 50, 'splitter': 'random'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.632 (std: 0.007)\n",
      "Parameters: {'class_weight': None, 'max_depth': 200, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 100, 'splitter': 'random'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gridsearch(X_train_tf,data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_impurity_split', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'presort', 'random_state', 'splitter'])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params().keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
